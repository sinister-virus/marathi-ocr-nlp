# -*- coding: utf-8 -*-
"""NLP_TA2_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H_gSiLA782Xl8C6yJXRqtekrumyioHhJ

# TA2: Handwritten Text Recognition and NLP Processing in Native Language

## Steps to Follow:

> 1. **Capture or upload** an image of a handwritten page written in your mother tongue.

> 2. **Preprocess the image** to improve clarity (e.g., convert to grayscale, resize, denoise).

> 3.  **Use OCR** to extract text from the image (e.g., Tesseract OCR with language pack for your language).

> 4. **Normalize** the extracted text (remove noise, unwanted characters, fix encoding issues).

> 5. **Tokenize** the text using an appropriate NLP tokenizer for your language.

> 6. **Perform one NLP task**, such as:
>    - Language detection
>    - Translation
>    - Summarization
>    - Named Entity Recognition (NER)

> 7. **Display the final output** in a readable format (console, notebook cell, or GUI).

### Step 0: Install & Import Required Libraries
"""

# Install All Required Python Libraries

!pip install gdown
!pip install indic-nlp-library
!pip install pytesseract
!pip install opencv-python-headless
!pip install googletrans==4.0.0-rc1
!pip install deep-translator

# Update and Install All Required Libraries and Tools

!sudo apt-get update
!sudo apt-get upgrade
!sudo apt-get install -y tesseract-ocr
!sudo apt-get install -y tesseract-ocr-mar
!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git

# Import All Required Libraries

import gdown
from google.colab import files
from PIL import Image
import numpy as np
import cv2
import pytesseract
import re
import pandas as pd
import matplotlib.pyplot as plt
from deep_translator import GoogleTranslator
from indicnlp.tokenize.indic_tokenize import trivial_tokenize

"""### Step 1: Upload Image"""

import gdown
from PIL import Image
from google.colab import files

# Option for the user to try dynamic upload quickly
user_choice = input("Would you like to skip static image and upload a dynamic image? (y/n) [default: n]: ").strip().lower()

if user_choice == 'y':
    print("Proceeding with dynamic image upload...")
    # Dynamic Image Uploads
    uploaded = files.upload()  # Upload image from user
    filename = list(uploaded.keys())[0]  # Get the name of the uploaded file

    # Open image with PIL
    img_pil = Image.open(filename)
    img_pil.show()

else:
    # Static Image Uploads
    file_id = '1z526YFcKb2g8HftFLPhH9Gg25I-jNtHh'  # Extract the file ID from the shared link
    url = f'https://drive.google.com/uc?export=download&id={file_id}'

    try:
        # Try downloading the static image using gdown
        gdown.download(url, 'marathi.gif', quiet=False)

        # Open the image with PIL
        img_pil = Image.open('marathi.gif')
        img_pil.show()

    except Exception as e:
        # If static image download fails, handle with dynamic image upload
        print(f"Static image download failed with error: {e}")
        print("Proceeding with dynamic image upload...")

        # Dynamic Image Uploads
        uploaded = files.upload()  # Upload image from user
        filename = list(uploaded.keys())[0]  # Get the name of the uploaded file

        # Open image with PIL
        img_pil = Image.open(filename)
        img_pil.show()

"""### Step 2: Preprocess Image"""

# Convert PIL to OpenCV format
img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# Preprocess image
gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
blurred = cv2.GaussianBlur(gray, (3, 3), 0)
_, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

#Show the preprocessed image
plt.imshow(thresh, cmap='gray')
plt.title("Preprocessed Image")
plt.axis('off')
plt.show()

"""### Step 3: OCR Extraction"""

# OCR with Marathi language
custom_config = r'--oem 3 --psm 6'
ocr_text = pytesseract.image_to_string(thresh, lang='mar', config=custom_config)
print("OCR Text (Marathi):\n", ocr_text)

"""### Step 4: Normalize Text"""

# Normalize the OCR output
normalized_text = re.sub(r'[^\u0900-\u097F\s]', '', ocr_text)
normalized_text = re.sub(r'\s+', ' ', normalized_text).strip()
print("\nNormalized Marathi Text:\n", normalized_text)

"""### Step 5: Tokenization"""

# Tokenization

# Simple whitespace tokenizer
tokens_simple = normalized_text.split()
print("\nTokenized Words (Simple Split):\n", tokens_simple)

# Advanced Indic NLP tokenizer
tokens_advanced = trivial_tokenize(normalized_text, lang='mar')
print("\nTokenized Words (Indic NLP):\n", tokens_advanced)

tokens = tokens_advanced

"""### Step 6: Translation"""

# Convert Marathi numbers to English numbers in text and tokens
devanagari_to_english_digits = {
    '०': '0', '१': '1', '२': '2', '३': '3', '४': '4',
    '५': '5', '६': '6', '७': '7', '८': '8', '९': '9'
}

def convert_devanagari_numbers(text):
    return re.sub(r'[\u0966-\u096F]+', lambda m: ''.join(devanagari_to_english_digits.get(ch, ch) for ch in m.group()), text)

# Translate full text
normalized_with_english_digits = convert_devanagari_numbers(normalized_text)
translation_text = GoogleTranslator(source='mr', target='en').translate(normalized_with_english_digits)
print("\nEnglish Translated Text:\n", translation_text)

# Translate individual tokens
translated_tokens = []
for token in tokens:
    if re.fullmatch(r'[\u0966-\u096F]+', token):
        translated_tokens.append(convert_devanagari_numbers(token))
    else:
        try:
            translated = GoogleTranslator(source='mr', target='en').translate(token)
            translated_tokens.append(translated)
        except:
            translated_tokens.append(token)

print("\nTranslated Tokens with Marathi Numbers Converted:\n", translated_tokens)

"""### Step 7: Final Output"""

# Display the image
plt.imshow(img_pil)
plt.axis('off')
plt.title("Uploaded Image")
plt.show()

# Final Output
print("\nFinal Output Summary:\n")
print("Original Marathi OCR Text:\n", normalized_text) # OCR Marathi Text
print("\nMarathi to English Translation:\n", translation_text) # English Translated Text
print("\nTokens in Marathi:\n", tokens) # Marathi Tokens
print("\nTranslated Tokens in English:\n", translated_tokens) # English Tokens

# Show tokens in tabular format
df = pd.DataFrame({'Marathi': tokens, 'English': translated_tokens})
df